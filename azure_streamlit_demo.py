#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LangChain å¯¹è¯Demo - Azure OpenAI Streamlit Webç•Œé¢ç‰ˆæœ¬
è¿è¡Œå‘½ä»¤: streamlit run azure_streamlit_demo.py
"""

import os
import streamlit as st
from dotenv import load_dotenv
from langchain_openai import AzureChatOpenAI
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.prompts import PromptTemplate

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="LangChain Azure OpenAI å¯¹è¯Demo",
    page_icon="ğŸ¤–",
    layout="wide"
)

# åˆå§‹åŒ–session state
if "messages" not in st.session_state:
    st.session_state.messages = []

if "conversation" not in st.session_state:
    st.session_state.conversation = None


def init_conversation():
    """åˆå§‹åŒ–å¯¹è¯é“¾"""
    try:
        # æ£€æŸ¥Azure OpenAIé…ç½®
        azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        azure_api_key = os.getenv("AZURE_OPENAI_API_KEY")
        azure_deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
        azure_api_version = os.getenv("AZURE_OPENAI_API_VERSION")

        if not all([azure_endpoint, azure_api_key, azure_deployment]):
            st.error("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®Azure OpenAIç›¸å…³é…ç½®")
            return None

        # åˆå§‹åŒ–AzureChatOpenAI
        llm = AzureChatOpenAI(
            azure_endpoint=azure_endpoint,
            azure_deployment=azure_deployment,
            api_key=azure_api_key,
            api_version=azure_api_version,
            temperature=0.08,
            max_tokens=None,
            timeout=None,
            max_retries=2,
        )

        # è®¾ç½®å¯¹è¯è®°å¿†
        memory = ConversationBufferMemory()

        # åˆ›å»ºå¯¹è¯é“¾
        template = """ä»¥ä¸‹æ˜¯äººç±»å’ŒAIä¹‹é—´çš„å‹å¥½å¯¹è¯ã€‚AIæ˜¯å¥è°ˆçš„ï¼Œå¹¶æä¾›äº†å¾ˆå¤šå…·ä½“çš„ç»†èŠ‚ã€‚å¦‚æœAIä¸çŸ¥é“é—®é¢˜çš„ç­”æ¡ˆï¼Œå®ƒä¼šè¯šå®åœ°è¯´å®ƒä¸çŸ¥é“ã€‚

å½“å‰å¯¹è¯:
{history}
äººç±»: {input}
AI:"""

        prompt = PromptTemplate(
            input_variables=["history", "input"],
            template=template
        )

        conversation = ConversationChain(
            llm=llm,
            memory=memory,
            prompt=prompt,
            verbose=False
        )

        return conversation
    except Exception as e:
        st.error(f"åˆå§‹åŒ–å¤±è´¥: {e}")
        return None


def main():
    st.title("ğŸ¤– LangChain Azure OpenAI å¯¹è¯Demo")

    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    if os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"):
        st.info(
            f"ğŸ”§ å½“å‰éƒ¨ç½²: {os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')} | APIç‰ˆæœ¬: {os.getenv('AZURE_OPENAI_API_VERSION')}")

    st.markdown("---")

    # åˆå§‹åŒ–å¯¹è¯é“¾
    if st.session_state.conversation is None:
        st.session_state.conversation = init_conversation()

    if st.session_state.conversation is None:
        st.stop()

    # ä¾§è¾¹æ è®¾ç½®
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")

        # æ¸©åº¦æ§åˆ¶
        temperature = st.slider(
            "æ¸©åº¦ (Temperature)",
            min_value=0.0,
            max_value=2.0,
            value=0.08,
            step=0.01,
            help="æ§åˆ¶å›å¤çš„éšæœºæ€§ï¼Œè¶Šé«˜è¶Šæœ‰åˆ›æ„"
        )

        # æ›´æ–°æ¸©åº¦è®¾ç½®
        if hasattr(st.session_state.conversation.llm, 'temperature'):
            st.session_state.conversation.llm.temperature = temperature

        if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯å†å²"):
            st.session_state.messages = []
            st.session_state.conversation.memory.clear()
            st.rerun()

        st.markdown("---")
        st.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        1. åœ¨èŠå¤©æ¡†ä¸­è¾“å…¥æ‚¨çš„é—®é¢˜
        2. æŒ‰Enteræˆ–ç‚¹å‡»å‘é€æŒ‰é’®
        3. AIä¼šæ ¹æ®ä¸Šä¸‹æ–‡å›å¤æ‚¨
        4. å¯ä»¥è°ƒæ•´æ¸©åº¦æ§åˆ¶å›å¤é£æ ¼
        5. ç‚¹å‡»"æ¸…é™¤å¯¹è¯å†å²"é‡æ–°å¼€å§‹
        """)

        st.markdown("---")
        st.markdown("### â„¹ï¸ é…ç½®ä¿¡æ¯")
        if os.getenv("AZURE_OPENAI_ENDPOINT"):
            st.text(f"ç«¯ç‚¹: {os.getenv('AZURE_OPENAI_ENDPOINT')}")
        if os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"):
            st.text(f"éƒ¨ç½²: {os.getenv('AZURE_OPENAI_DEPLOYMENT_NAME')}")
        if os.getenv("AZURE_OPENAI_API_VERSION"):
            st.text(f"APIç‰ˆæœ¬: {os.getenv('AZURE_OPENAI_API_VERSION')}")

    # æ˜¾ç¤ºèŠå¤©å†å²
    chat_container = st.container()
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # èŠå¤©è¾“å…¥
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        st.session_state.messages.append({"role": "user", "content": prompt})

        # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message("user"):
            st.markdown(prompt)

        # è·å–AIå›å¤
        with st.chat_message("assistant"):
            with st.spinner("AIæ­£åœ¨æ€è€ƒ..."):
                try:
                    response = st.session_state.conversation.predict(input=prompt)
                    st.markdown(response)

                    # æ·»åŠ AIå›å¤åˆ°å†å²
                    st.session_state.messages.append({"role": "assistant", "content": response})

                except Exception as e:
                    error_msg = f"æŠ±æ­‰ï¼Œå‘ç”Ÿäº†é”™è¯¯: {e}"
                    st.error(error_msg)
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})


if __name__ == "__main__":
    main()