#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºAzure OpenAIçš„RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) Demo
å®ç°è·å–æœ€æ–°æ¶ˆæ¯å¹¶æä¾›ç»™å¤§æ¨¡å‹çš„åŠŸèƒ½
"""

import os
import json
from datetime import datetime, timedelta
from typing import List, Dict, Any
from dotenv import load_dotenv

# LangChain imports
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.prompts import ChatPromptTemplate
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class MessageRetriever:
    """æ¶ˆæ¯æ£€ç´¢å™¨ - æ¨¡æ‹Ÿä»å„ç§æ•°æ®æºè·å–æœ€æ–°æ¶ˆæ¯"""

    def __init__(self):
        # è¿™é‡Œæ¨¡æ‹Ÿä¸€äº›æ•°æ®æºï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥æ˜¯ï¼š
        # - æ•°æ®åº“æŸ¥è¯¢
        # - APIè°ƒç”¨
        # - æ–‡ä»¶è¯»å–
        # - å®æ—¶æ•°æ®æµç­‰
        self.data_sources = {
            "news": self._get_latest_news,
            "company_updates": self._get_company_updates,
            "market_data": self._get_market_data,
            "user_messages": self._get_user_messages
        }

    def _get_latest_news(self) -> List[Dict[str, Any]]:
        """è·å–æœ€æ–°æ–°é—»ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        # å®é™…å®ç°ä¸­ï¼Œè¿™é‡Œå¯ä»¥è°ƒç”¨æ–°é—»API
        return [
            {
                "title": "äººå·¥æ™ºèƒ½æŠ€æœ¯çªç ´",
                "content": "æœ€æ–°çš„AIæ¨¡å‹åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­åˆ›ä¸‹æ–°çºªå½•ï¼Œæ˜¾ç¤ºå‡ºå¼ºå¤§çš„æ¨ç†èƒ½åŠ›ã€‚",
                "timestamp": datetime.now() - timedelta(hours=2),
                "source": "tech_news",
                "category": "technology"
            },
            {
                "title": "äº‘è®¡ç®—å¸‚åœºå¢é•¿",
                "content": "2024å¹´äº‘è®¡ç®—å¸‚åœºé¢„è®¡å°†å¢é•¿25%ï¼Œä¸»è¦é©±åŠ¨åŠ›æ¥è‡ªAIå’Œæ•°æ®åˆ†æéœ€æ±‚ã€‚",
                "timestamp": datetime.now() - timedelta(hours=1),
                "source": "business_news",
                "category": "business"
            }
        ]

    def _get_company_updates(self) -> List[Dict[str, Any]]:
        """è·å–å…¬å¸æ›´æ–°ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        return [
            {
                "title": "æ–°äº§å“å‘å¸ƒ",
                "content": "å…¬å¸å°†äºä¸‹æœˆå‘å¸ƒåŸºäºAIçš„æ–°ä¸€ä»£å®¢æˆ·æœåŠ¡å¹³å°ï¼Œé¢„è®¡å°†æé«˜æ•ˆç‡30%ã€‚",
                "timestamp": datetime.now() - timedelta(hours=3),
                "source": "internal",
                "category": "product"
            }
        ]

    def _get_market_data(self) -> List[Dict[str, Any]]:
        """è·å–å¸‚åœºæ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        return [
            {
                "title": "è‚¡å¸‚åŠ¨æ€",
                "content": "ç§‘æŠ€è‚¡ä»Šæ—¥ä¸Šæ¶¨2.5%ï¼ŒAIç›¸å…³å…¬å¸è¡¨ç°çªå‡ºã€‚æŠ•èµ„è€…å¯¹æ–°æŠ€æœ¯å‰æ™¯ä¿æŒä¹è§‚ã€‚",
                "timestamp": datetime.now() - timedelta(minutes=30),
                "source": "market_feed",
                "category": "finance"
            }
        ]

    def _get_user_messages(self) -> List[Dict[str, Any]]:
        """è·å–ç”¨æˆ·æ¶ˆæ¯ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        return [
            {
                "title": "ç”¨æˆ·åé¦ˆ",
                "content": "ç”¨æˆ·åæ˜ æ–°ç‰ˆæœ¬ç•Œé¢æ›´åŠ å‹å¥½ï¼Œä½†å¸Œæœ›å¢åŠ æ›´å¤šè‡ªå®šä¹‰é€‰é¡¹ã€‚",
                "timestamp": datetime.now() - timedelta(hours=4),
                "source": "user_feedback",
                "category": "feedback"
            }
        ]

    def get_latest_messages(self, hours_back: int = 24, categories: List[str] = None) -> List[Dict[str, Any]]:
        """è·å–æœ€æ–°æ¶ˆæ¯"""
        all_messages = []
        cutoff_time = datetime.now() - timedelta(hours=hours_back)

        for source_name, source_func in self.data_sources.items():
            messages = source_func()
            for msg in messages:
                if msg["timestamp"] >= cutoff_time:
                    if categories is None or msg["category"] in categories:
                        all_messages.append(msg)

        # æŒ‰æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        all_messages.sort(key=lambda x: x["timestamp"], reverse=True)
        return all_messages


class AzureRAGDemo:
    """åŸºäºAzure OpenAIçš„RAGæ¼”ç¤ºç±»"""

    def __init__(self):
        # æ£€æŸ¥Azure OpenAIé…ç½®
        azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
        azure_api_key = os.getenv("AZURE_OPENAI_API_KEY")
        azure_deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
        azure_api_version = os.getenv("AZURE_OPENAI_API_VERSION")
        print(f"åˆå§‹åŒ–Azure OpenAIç»„ä»¶...", azure_endpoint, azure_api_key, azure_deployment, azure_api_version)
        if not all([azure_endpoint, azure_api_key, azure_deployment]):
            raise ValueError("è¯·åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®Azure OpenAIç›¸å…³é…ç½®")

        # åˆå§‹åŒ–Azure OpenAIç»„ä»¶
        self.llm = AzureChatOpenAI(
            azure_endpoint=azure_endpoint,
            azure_deployment=azure_deployment,
            api_key=azure_api_key,
            api_version=azure_api_version,
            temperature=0.1,
            max_tokens=None,
        )

        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ï¼ˆéœ€è¦å•ç‹¬çš„åµŒå…¥æ¨¡å‹éƒ¨ç½²ï¼‰
        # å¦‚æœæ²¡æœ‰åµŒå…¥æ¨¡å‹éƒ¨ç½²ï¼Œå¯ä»¥ä½¿ç”¨OpenAIçš„åµŒå…¥API
        try:
            self.embeddings = AzureOpenAIEmbeddings(
                azure_endpoint=azure_endpoint,
                azure_deployment=os.getenv("AZURE_OPENAI_EMBEDDING_DEPLOYMENT", "text-embedding-ada-002"),
                api_key=azure_api_key,
                api_version=azure_api_version,
            )
        except:
            print("è­¦å‘Š: æ— æ³•åˆå§‹åŒ–AzureåµŒå…¥æ¨¡å‹ï¼Œå°†ä½¿ç”¨OpenAIåµŒå…¥æ¨¡å‹")
            from langchain_openai import OpenAIEmbeddings
            self.embeddings = OpenAIEmbeddings()

        # åˆå§‹åŒ–æ¶ˆæ¯æ£€ç´¢å™¨
        self.message_retriever = MessageRetriever()

        # åˆå§‹åŒ–å‘é‡å­˜å‚¨
        self.vector_store = None
        self.retriever = None

        # è®¾ç½®RAGé“¾
        self._setup_rag_chain()

    def _setup_rag_chain(self):
        """è®¾ç½®RAGé“¾"""
        # åˆ›å»ºRAGæç¤ºæ¨¡æ¿
        rag_prompt = ChatPromptTemplate.from_template("""
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“é—¨ç”¨äºå›ç­”åŸºäºæœ€æ–°ä¿¡æ¯çš„é—®é¢˜ã€‚

è¯·åŸºäºä»¥ä¸‹æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š

ä¸Šä¸‹æ–‡ä¿¡æ¯:
{context}

ç”¨æˆ·é—®é¢˜: {input}

è¯·æ³¨æ„ï¼š
1. è¯·ä¸»è¦åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯æ¥å›ç­”
2. å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. å›ç­”è¦å‡†ç¡®ã€ç®€æ´ã€æœ‰ç”¨
4. å¦‚æœå¯èƒ½ï¼Œè¯·æåŠä¿¡æ¯çš„æ—¶é—´å’Œæ¥æº

å›ç­”:
""")

        # åˆ›å»ºæ–‡æ¡£ç»„åˆé“¾
        self.combine_docs_chain = create_stuff_documents_chain(
            self.llm, rag_prompt
        )

    def update_knowledge_base(self, hours_back: int = 24, categories: List[str] = None):
        """æ›´æ–°çŸ¥è¯†åº“withæœ€æ–°æ¶ˆæ¯"""
        print(f"æ­£åœ¨è·å–è¿‡å»{hours_back}å°æ—¶çš„æœ€æ–°æ¶ˆæ¯...")

        # è·å–æœ€æ–°æ¶ˆæ¯
        latest_messages = self.message_retriever.get_latest_messages(
            hours_back=hours_back,
            categories=categories
        )

        if not latest_messages:
            print("æ²¡æœ‰æ‰¾åˆ°æœ€æ–°æ¶ˆæ¯")
            return

        print(f"æ‰¾åˆ° {len(latest_messages)} æ¡æœ€æ–°æ¶ˆæ¯")

        # å°†æ¶ˆæ¯è½¬æ¢ä¸ºæ–‡æ¡£
        documents = []
        for msg in latest_messages:
            # åˆ›å»ºåŒ…å«å…ƒæ•°æ®çš„æ–‡æ¡£
            doc_content = f"æ ‡é¢˜: {msg['title']}\nå†…å®¹: {msg['content']}"
            metadata = {
                "title": msg["title"],
                "timestamp": msg["timestamp"].isoformat(),
                "source": msg["source"],
                "category": msg["category"]
            }
            documents.append(Document(page_content=doc_content, metadata=metadata))

        # æ–‡æœ¬åˆ†å‰²ï¼ˆå¦‚æœæ¶ˆæ¯å¾ˆé•¿ï¼‰
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            add_start_index=True,
        )
        splits = text_splitter.split_documents(documents)

        # åˆ›å»ºæˆ–æ›´æ–°å‘é‡å­˜å‚¨
        print("æ­£åœ¨æ„å»ºå‘é‡å­˜å‚¨...")
        self.vector_store = Chroma.from_documents(
            documents=splits,
            embedding=self.embeddings,
            collection_name="latest_messages"
        )

        # åˆ›å»ºæ£€ç´¢å™¨
        self.retriever = self.vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 3}  # è¿”å›æœ€ç›¸å…³çš„3ä¸ªæ–‡æ¡£
        )

        print("çŸ¥è¯†åº“æ›´æ–°å®Œæˆï¼")

    def chat_with_latest_info(self, question: str) -> str:
        """åŸºäºæœ€æ–°ä¿¡æ¯è¿›è¡Œå¯¹è¯"""
        if self.retriever is None:
            return "è¯·å…ˆè°ƒç”¨ update_knowledge_base() æ–¹æ³•æ¥æ„å»ºçŸ¥è¯†åº“"

        # åˆ›å»ºæ£€ç´¢é“¾
        retrieval_chain = create_retrieval_chain(
            self.retriever,
            self.combine_docs_chain
        )

        # æ‰§è¡Œæ£€ç´¢å’Œç”Ÿæˆ
        result = retrieval_chain.invoke({"input": question})

        return result["answer"]

    def get_relevant_context(self, question: str, k: int = 3) -> List[Document]:
        """è·å–ç›¸å…³ä¸Šä¸‹æ–‡æ–‡æ¡£"""
        if self.retriever is None:
            return []

        return self.retriever.invoke(question)

    def start_interactive_chat(self):
        """å¼€å§‹äº¤äº’å¼èŠå¤©"""
        print("ğŸ¤– Azure OpenAI RAG æ¼”ç¤º")
        print("åŸºäºæœ€æ–°æ¶ˆæ¯çš„æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
        print("-" * 50)

        # é¦–å…ˆæ›´æ–°çŸ¥è¯†åº“
        print("åˆå§‹åŒ–çŸ¥è¯†åº“...")
        self.update_knowledge_base()
        print()

        print("å¯ä»¥å¼€å§‹æé—®äº†ï¼")
        print("è¾“å…¥ 'quit', 'exit' æˆ– 'bye' æ¥é€€å‡º")
        print("è¾“å…¥ 'update' æ¥æ›´æ–°çŸ¥è¯†åº“")
        print("è¾“å…¥ 'context <é—®é¢˜>' æ¥æŸ¥çœ‹ç›¸å…³ä¸Šä¸‹æ–‡")
        print("-" * 50)

        while True:
            try:
                user_input = input("\næ‚¨: ").strip()

                if user_input.lower() in ['quit', 'exit', 'bye', 'é€€å‡º']:
                    print("AI: å†è§ï¼")
                    break

                if not user_input:
                    continue

                if user_input.lower() == 'update':
                    print("æ›´æ–°çŸ¥è¯†åº“...")
                    self.update_knowledge_base()
                    print("çŸ¥è¯†åº“å·²æ›´æ–°ï¼")
                    continue

                if user_input.lower().startswith('context '):
                    question = user_input[8:]
                    docs = self.get_relevant_context(question)
                    print(f"\næ‰¾åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£:")
                    for i, doc in enumerate(docs, 1):
                        print(f"\næ–‡æ¡£ {i}:")
                        print(f"å†…å®¹: {doc.page_content[:200]}...")
                        print(f"å…ƒæ•°æ®: {doc.metadata}")
                    continue

                # æ­£å¸¸é—®ç­”
                print("\nAI: ", end="", flush=True)
                response = self.chat_with_latest_info(user_input)
                print(response)

            except KeyboardInterrupt:
                print("\n\nAI: å†è§ï¼")
                break
            except Exception as e:
                print(f"\nå‘ç”Ÿé”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    try:
        demo = AzureRAGDemo()
        demo.start_interactive_chat()
    except ValueError as e:
        print(f"é…ç½®é”™è¯¯: {e}")
        print("\nè¯·ç¡®ä¿å·²åˆ›å»º .env æ–‡ä»¶å¹¶è®¾ç½®äº†ä»¥ä¸‹é…ç½®ï¼š")
        print("- AZURE_OPENAI_ENDPOINT")
        print("- AZURE_OPENAI_API_KEY")
        print("- AZURE_OPENAI_DEPLOYMENT_NAME")
        print("- AZURE_OPENAI_API_VERSION")
        print("- AZURE_OPENAI_EMBEDDING_DEPLOYMENT (å¯é€‰)")
    except Exception as e:
        print(f"åˆå§‹åŒ–å¤±è´¥: {e}")


if __name__ == "__main__":
    main()